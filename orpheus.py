# -*- coding: utf-8 -*-
"""Orpheus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IEHZU_7E0yxhl1gSf3j7XiNgGAnLhGUS
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Reshape, Flatten, Dropout

def build_generator(seq_length=100, latent_dim=50):
    model = Sequential()

    model.add(Dense(128, activation="relu", input_dim=latent_dim))
    model.add(Reshape((seq_length, 1)))  # Reshape para o formato que o LSTM espera
    model.add(LSTM(128, return_sequences=True))
    model.add(Dropout(0.2))
    model.add(LSTM(128))
    model.add(Dense(seq_length, activation="tanh"))  # Produzindo uma sequência de melodia

    return model

def build_discriminator(seq_length=1000):
    model = Sequential()

    model.add(Reshape((seq_length, 1), input_shape=(seq_length,)))
    model.add(LSTM(128, return_sequences=True))
    model.add(Dropout(0.2))
    model.add(LSTM(128))
    model.add(Dense(1, activation="sigmoid"))  # Classificação binária: real ou falso

    return model



import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, Reshape, Flatten, Dropout, Input

def build_generator(seq_length=100, latent_dim=50):
    model = Sequential()

    model.add(Dense(seq_length, activation="relu", input_dim=latent_dim))
    model.add(Reshape((seq_length, 1)))
    model.add(LSTM(128, return_sequences=True))
    model.add(Dropout(0.2))
    model.add(LSTM(128))
    model.add(Dense(seq_length, activation="tanh"))

    return model

def build_discriminator(seq_length=1000):
    model = Sequential()

    model.add(Reshape((seq_length, 1), input_shape=(seq_length,)))
    model.add(LSTM(128, return_sequences=True))
    model.add(Dropout(0.2))
    model.add(LSTM(128))
    model.add(Flatten())
    model.add(Dense(1, activation="sigmoid"))

    return model

def compile_gan(generator, discriminator, latent_dim=50):
    discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    z = Input(shape=(latent_dim,))
    melody = generator(z)
    discriminator.trainable = False
    valid = discriminator(melody)
    gan = Model(z, valid)
    gan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return gan

# Inicialize os modelos
generator = build_generator()
discriminator = build_discriminator()
gan = compile_gan(generator, discriminator)

def train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim=50):
    for epoch in range(epochs):
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        generated_sequences = generator.predict(noise)

        # Carregue seus dados aqui
        real_sequences = np.random.normal(0, 1, (batch_size, 100))  # Substitua isso pelo seu dataset

        d_loss_real = discriminator.train_on_batch(real_sequences, np.ones((batch_size, 1)))
        d_loss_fake = discriminator.train_on_batch(generated_sequences, np.zeros((batch_size, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))

        print(f"Epoch: {epoch} | D Loss: {d_loss[0]} | G Loss: {g_loss[0]}")

# Chamando a função de treinamento
train_gan(generator, discriminator, gan, epochs=100, batch_size=32)

import os
import numpy as np
import pretty_midi
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dense, Flatten, Input, Dropout
from tensorflow.keras.optimizers import Adam


# Pre-processamento: De MIDI para Pianoroll
def midi_to_pianoroll(midi_file, fs=10):
    midi = pretty_midi.PrettyMIDI(midi_file)
    piano = midi.instruments[0]  # Pega o primeiro instrumento
    pianoroll = piano.get_piano_roll(fs=fs)
    return (pianoroll > 0).astype(int)

# Pós-processamento: De Pianoroll para MIDI
def pianoroll_to_midi(pianoroll, fs=10):
    midi = pretty_midi.PrettyMIDI()
    instrument = pretty_midi.Instrument(program=0)
    for pitch, active in enumerate(pianoroll):
        for i in range(len(active) - 1):
            if active[i] == 1 and active[i + 1] == 0:
                start_time = i / fs
                for j in range(i, len(active)):
                    if active[j] == 0:
                        end_time = j / fs
                        break
                note = pretty_midi.Note(velocity=100, pitch=pitch, start=start_time, end=end_time)
                instrument.notes.append(note)
    midi.instruments.append(instrument)
    return midi

def standardize_pianoroll_length(pianoroll, length=1000):
    """Standardize the length of a pianoroll. Truncate or zero-pad as necessary."""
    if pianoroll.shape[1] > length:
        return pianoroll[:, :length].T
    elif pianoroll.shape[1] < length:
        padding = np.zeros((length - pianoroll.shape[1], pianoroll.shape[0]))
        return np.vstack((pianoroll.T, padding))
    else:
        return pianoroll.T


# GAN

def build_generator(seq_length=1000, latent_dim=50):
    model = Sequential()
    model.add(Dense(seq_length * 128, activation="relu", input_dim=latent_dim))
    model.add(Reshape((seq_length, 128)))
    model.add(LSTM(128, return_sequences=True))
    model.add(Dropout(0.2))
    model.add(Dense(128, activation="tanh"))
    return model

def build_discriminator(seq_length=1000):
    model = Sequential()
    model.add(LSTM(128, return_sequences=True, input_shape=(seq_length, 128)))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(1, activation="sigmoid"))
    return model

def compile_gan(generator, discriminator):
    discriminator.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])
    noise = Input(shape=(50,))
    seq = generator(noise)
    discriminator.trainable = False
    validity = discriminator(seq)
    gan = Model(noise, validity)
    gan.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])
    return gan

def train_gan(generator, discriminator, gan, pianorolls, epochs, batch_size, latent_dim=50):
    valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))
    for epoch in range(epochs):
        idx = np.random.randint(0, pianorolls.shape[0], batch_size)
        real_seqs = pianorolls[idx]
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        generated_seqs = generator.predict(noise)
        d_loss_real = discriminator.train_on_batch(real_seqs, valid)
        d_loss_fake = discriminator.train_on_batch(generated_seqs, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        g_loss = gan.train_on_batch(noise, valid)
        print(f"Epoch: {epoch} | D Loss: {d_loss[0]} | G Loss: {g_loss[0]}")

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_size, num_heads, ff_dim, dropout=0.1):
        super(TransformerBlock, self).__init__()
        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_size)
        self.norm1 = LayerNormalization(epsilon=1e-6)
        self.norm2 = LayerNormalization(epsilon=1e-6)
        self.ffn = Sequential(
            [Dense(ff_dim, activation="relu"), Dense(embed_size),]
        )
        self.dropout1 = Dropout(dropout)
        self.dropout2 = Dropout(dropout)

    def call(self, inputs, training):
        attn_output = self.attention(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.norm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.norm2(out1 + ffn_output)

def build_generator_with_transformer(seq_length=1000, latent_dim=50, embed_size=128, num_heads=8, ff_dim=32):
    model = Sequential()
    model.add(Dense(seq_length * embed_size, activation="relu", input_dim=latent_dim))
    model.add(Reshape((seq_length, embed_size)))

    # Adicione o bloco Transformer
    model.add(TransformerBlock(embed_size, num_heads, ff_dim))

    model.add(Dropout(0.2))
    model.add(Dense(128, activation="tanh"))
    return model






# 1. Carregue os seus arquivos MIDI e converta-os para Pianorolls.
directory_path = '.'  # Seus arquivos MIDI devem estar neste diretório.
midi_files = ["bach_846.mid", "bach_847.mid", "bach_850.mid"]
piano_rolls_list = []

for midi_file in midi_files:
    path = os.path.join(directory_path, midi_file)
    pianoroll = midi_to_pianoroll(path)
    standardized_pianoroll = standardize_pianoroll_length(pianoroll)
    piano_rolls_list.append(standardized_pianoroll)

pianorolls = np.stack(piano_rolls_list)

# 2. Construa a GAN.
'''
generator = build_generator()
discriminator = build_discriminator()
gan = compile_gan(generator, discriminator)
'''
# 2. Construa a GAN com o Transformer como gerador.
generator = build_generator_with_transformer()
discriminator = build_discriminator()
gan = compile_gan(generator, discriminator)

# 3. Treine a GAN.
train_gan(generator, discriminator, gan, pianorolls, epochs=1000, batch_size=32)

'''
# 4. Gere e ouça uma melodia.
noise = np.random.normal(0, 1, (1, 50))
generated_sequence = generator.predict(noise)
generated_midi = pianoroll_to_midi(generated_sequence[0])
generated_midi.write('generated_song.mid')
'''
noise = np.random.normal(0, 1, (1, 50))
generated_sequence = generator.predict(noise)
generated_midi = pianoroll_to_midi(generated_sequence[0])
generated_midi.write('generated_song.mid')

import os
import numpy as np
import pretty_midi
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dense, Flatten, Input, Dropout
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping


def midi_to_pianoroll(midi_file, fs=10):
    midi = pretty_midi.PrettyMIDI(midi_file)
    piano = midi.instruments[0]
    pianoroll = piano.get_piano_roll(fs=fs)
    return (pianoroll > 0).astype(int)

def pianoroll_to_midi(pianoroll, fs=10):
    midi = pretty_midi.PrettyMIDI()
    instrument = pretty_midi.Instrument(program=0)
    for pitch, active in enumerate(pianoroll):
        for i in range(len(active) - 1):
            if active[i] == 1 and active[i + 1] == 0:
                start_time = i / fs
                for j in range(i, len(active)):
                    if active[j] == 0:
                        end_time = j / fs
                        break
                note = pretty_midi.Note(velocity=100, pitch=pitch, start=start_time, end=end_time)
                instrument.notes.append(note)
    midi.instruments.append(instrument)
    return midi

def standardize_pianoroll_length(pianoroll, length=1000):
    """Standardize the length of a pianoroll. Truncate or zero-pad as necessary."""
    if pianoroll.shape[1] > length:
        return pianoroll[:, :length].T
    elif pianoroll.shape[1] < length:
        padding = np.zeros((length - pianoroll.shape[1], pianoroll.shape[0]))
        return np.vstack((pianoroll.T, padding))
    else:
        return pianoroll.T

directory_path = '.'
midi_files = ["bach_846.mid", "bach_847.mid", "bach_850.mid","alb_esp1.mid","alb_esp2.mid","alb_esp3.mid","alb_esp4.mid","alb_esp5.mid",
              "alb_esp6.mid","appass_1.mid","beethoven_hammerklavier_1.mid","beethoven_hammerklavier_2.mid","beethoven_hammerklavier_3.mid",
              "beethoven_hammerklavier_4.mid","beethoven_les_adieux_1.mid","beethoven_opus10_3.mid","beethoven_opus22_1.mid","beethoven_opus90_2.mid",
              "elise.mid","islamei.mid","pathetique_2.mid","waldstein_2.mid"]  # Substitua por seus arquivos MIDI
piano_rolls_list = []

for midi_file in midi_files:
    path = os.path.join(directory_path, midi_file)
    pianoroll = midi_to_pianoroll(path)
    standardized_pianoroll = standardize_pianoroll_length(pianoroll)
    piano_rolls_list.append(standardized_pianoroll)

pianorolls = np.stack(piano_rolls_list)


class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_size, num_heads, ff_dim, dropout=0.1):
        super(TransformerBlock, self).__init__()
        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_size)
        self.norm1 = LayerNormalization(epsilon=1e-6)
        self.norm2 = LayerNormalization(epsilon=1e-6)
        self.ffn = Sequential(
            [Dense(ff_dim, activation="relu"), Dense(embed_size),]
        )
        self.dropout1 = Dropout(dropout)
        self.dropout2 = Dropout(dropout)

    def call(self, inputs, training):
        attn_output = self.attention(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.norm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.norm2(out1 + ffn_output)

def build_transformer_model(seq_length=500, embed_size=64, num_heads=4, ff_dim=16, num_blocks=2):
    inputs = Input(shape=(seq_length, embed_size))
    x = inputs
    for _ in range(num_blocks):
        x = TransformerBlock(embed_size, num_heads, ff_dim)(x)
        x = Dropout(0.1)(x)
    x = Flatten()(x)
    outputs = Dense(embed_size, activation="softmax")(x)
    model = Model(inputs=inputs, outputs=outputs)
    return model

seq_length = 500
embed_size = 128
X = pianorolls[:, :seq_length-1, :embed_size]
y = pianorolls[:, seq_length-1, :embed_size]


model = build_transformer_model(seq_length=seq_length-1, embed_size=embed_size, num_blocks=3)  # Adicionando mais blocos Transformer
optimizer = RMSprop(learning_rate=0.001)
model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=["accuracy"])

reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)
early_stopping = EarlyStopping(monitor='loss', patience=10)

model.fit(X, y, epochs=100, batch_size=32, callbacks=[reduce_lr, early_stopping])
initial_sequence = X[0]
next_note = model.predict(np.expand_dims(initial_sequence, axis=0))

# Para prever a próxima nota de uma sequência
initial_sequence = X[0]
next_note = model.predict(np.expand_dims(initial_sequence, axis=0))
print("Previsão da próxima nota:", next_note)